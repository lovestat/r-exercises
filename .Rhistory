rexp(1)
rexp(1)
dexp(1)
dexp(0)
dexp(-5)
dexp(seq(-1, 10, 1000)) %>%
plot(seq(-1, 10, 1000), ., type = "l")
dexp(seq(-1, 10, 1000)) %>%
plot(seq(-1, 10, 1000), ., type = "line")
dexp(seq(-1, 10, 1000)) %>%
plot(seq(-1, 10, 1000), ., type = "l")
dexp(seq(-1, 10, 1000)) %>%
plot(seq(-1, 10, 1000), ., type = "l")
dexp(seq(-1, 10, 1000))
dexp(1:15)
seq(-1, 10, 1000)
seq(from = -1, to = 10, length.out = 1000)
x <- seq(from = -1, to = 10, length.out = 1000)
plot(x, rexp(x), type = 'l')
plot(x, dexp(x), type = 'l')
x <- seq(from = 0, to = 10, length.out = 1000)
plot(x, dexp(x), type = 'l')
?html_session()
shiny::runApp('C:/Users/ss/Downloads')
runApp('demo')
runApp('demo')
# generate bins based on input$bins from ui.R
x    <- faithful[, 2]
bins <- seq(min(x), max(x), length.out = input$bins + 1)
df <- data.frame(x = x)
# draw the histogram with the specified number of bins
# hist(x, breaks = bins, col = 'darkgray', border = 'white')
ggplot(df, aes(x = x)) +
geom_histogram(bins = bins)
# generate bins based on input$bins from ui.R
x    <- faithful[, 2]
bins <- 10
df <- data.frame(x = x)
# draw the histogram with the specified number of bins
# hist(x, breaks = bins, col = 'darkgray', border = 'white')
ggplot(df, aes(x = x)) +
geom_histogram(bins = bins)
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
length(x)
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runApp('demo')
runExample("01_hello")        # a histogram
runExample("02_text")         # tables and data frames
runExample("06_tabsets")      # tabbed panels
runApp('demo')
runApp('demo')
runExample("06_tabsets")      # tabbed panels
runExample("07_widgets")      # help text and submit buttons
runApp('crypto')
install.packages("crypto")
?rexp
?as_tibble
library(bench)
x <- runif(n = 1000000)
b <- bench::mark(
sqrt(x),
x ^ 0.5,
x ^ (1 / 2),
exp(log(x) / 2),
time_unit = 's'
)
b
summary(b, relative = TRUE)
summary(b, relative = TRUE)
system.time({
x <- c()
for (i in 1:100000) {
x <- c(x, rnorm(1)) + 5
}
})
#>    user  system elapsed
#>  15.459   8.144  23.656
system.time({
x <- numeric(length = 100000)
for (i in 1:100000) {
x[i] <- rnorm(1) + 5
}
})
#>    user  system elapsed
#>   0.172   0.029   0.201
system.time({
rnorm(100000) + 5
})
x <- data.frame(matrix(rnorm(100000), nrow = 1))
system_time({
types <- numeric(dim(x)[2])
for (i in seq_along(x)) {
types[i] <- typeof(x[i])
}
})
#> process    real
#>   10.1s   10.1s
system_time({
sapply(x, typeof)
})
#> process    real
#>    65ms  65.4ms
system_time({
purrr::map_chr(x, typeof)
})
nz_link <- "http://bit.ly/nz-data"
system_time({
read.csv(nz_link)
})
#>  process     real
#> 263.29ms    2.38s
system_time({
readr::read_csv(nz_link)
})
#> process    real
#>   183ms   452ms
system_time({
data.table::fread(nz_link)
})
#>  process     real
#> 167.29ms    1.22s
bike_link <- "http://www2.stat.duke.edu/~sms185/data/bike/2017q3.csv"
system_time({
read.csv(bike_link)
})
library(parallel)
detectCores()
system.time(rnorm(1e7) ^ 4)
system.time(rnorm(1e7) ^ 4)
#>    user  system elapsed
#>   0.824   0.019   0.845
system.time(pvec(v = rnorm(1e7), FUN = `^`, 4, mc.cores = 1))
#>    user  system elapsed
#>   0.797   0.015   0.814
system.time(pvec(v = rnorm(1e7), FUN = `^`, 4, mc.cores = 2))
system.time(rnorm(1e6))
#>   user  system elapsed
#>  0.101   0.007   0.107
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 2)))
#>   user  system elapsed
#>  0.148   0.136   0.106
system.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 4)))
?mclapply
apropos(parallel)
cl <- makeCluster(4)
system.time(clusterExport(cl, "jan2010"))
cl <- makeCluster(4)
clusterCall(cl, rnorm, 5)
cl <- makeCluster(16)
clusterCall(cl, rnorm, 5)
cl <- makeCluster(18)
clusterCall(cl, rnorm, 5)
cl <- makeCluster(8)
clusterCall(cl, rnorm, 5)
system.time(clusterCall(cl, rnorm, 5))
bench::mark(
clusterCall(cl, rnorm, 5)
)
bench::mark(
clusterCall(cl, rnorm, 5),
rnorm(40)
)
bench::mark(
clusterCall(cl, rnorm, 5),
rnorm(40)
)
bench::mark(
clusterCall(cl, rnorm, 5) %>% unlist(),
rnorm(40)
)
bench::mark(
1
)
bench::mark(
1,
2
)
clusterCall(cl, rnorm, 5)
clusterCall(cl, rnorm, 5) %>% unlist()
rnorm(40)
clusterCall(cl, (1:10000)^2) %>% unlist()
clusterCall(cl, sqrt, 5) %>% unlist()
clusterCall(cl, sqrt, 5)
clusterCall(cl, sqrt, 1:1e5) %>% unlist()
cl <- makeCluster(10)
rep(sqrt(1:1e5), 5)
bench::mark(
clusterCall(cl, sqrt, 1:1e5) %>% unlist()
rep(sqrt(1:1e5), 5)
)
bench::mark(
clusterCall(cl, sqrt, 1:1e5) %>% unlist(),
rep(sqrt(1:1e5), 5)
)
x <- 1:3
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(1:1e5), 5)
x <- 1:3
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(1:1e5), 5)
clusterCall(cl, sqrt, x)
clusterCall(cl, sqrt, x)
clusterCall(cl, sqrt, x) %>% unlist()
rep(sqrt(x), 5)
rep(sqrt(x), 10)
bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 10)
)
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 10)
)
p %>% DT:datatable()
library(DT)
p %>% DT:datatable()
p %>% DT::datatable()
p %>% DT::datatable()
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 10)
) %>% as_tibble()
p %>% DT::datatable()
p
p %>% view()
x <- 1:1e10
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 10)
) %>% as_tibble()
cl <- makeCluster(16)
x <- 1:1e7
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 10)
) %>% as_tibble()
x <- 1:1e4
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 16)
) %>% as_tibble()
p %>% view()
p
x <- 1:1e4
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 16)
) %>% as_tibble()
p
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 16)
)
p
x <- 1:1e8
p <- bench::mark(
clusterCall(cl, sqrt, x) %>% unlist(),
rep(sqrt(x), 16)
)
Sys.time()
Sys.time()
clust <- makeCluster(4)
library(parallel)
clust <- makeCluster(4)
library(nycflights13)
clusterEvalQ(cl = clust, dim(flights))
clusterEvalQ(cl = clust, dim(flights))
flights %>% attach()
library(tidyverse)
library(nycflights13)
flights %>% attach()
clusterEvalQ(cl = clust, dim(flights))
clusterEvalQ(cl = clust,
{library(nycflights13)
dim(flights)
}
)
?clusterEvalQ
dim(flights)
dim(flights)
parLapply(cl = clust,
1:100000,
sqrt)
parLapply(cl = clust,
1:100000,
sqrt) %>% system.time()
parLapply(cl = clust,
1:10000000,
sqrt) %>% system.time()
stopCluster(clust)
library(doMC)
library(foreach)
install.packages("doMC")
install.packages("foreach")
install.packages("doMC")
library(doMC)
library(foreach)
getDoParWorkers()
registerDoMC(4)
install.packages("doParallel")
library(doParallel)
registerDoParallel(8)
getDoParWorkers()
foreach(i = 1:4) %do%
sort(runif(n = 1e7, max = i))[1]
foreach(i = 1:4) %dopar%
sort(runif(n = 1e7, max = i))[1]
system.time({
foreach(i = 1:4) %do%
sort(runif(n = 1e7, max = i))[1]
})
system.time({
foreach(i = 1:4) %dopar%
sort(runif(n = 1e7, max = i))[1]
})
system.time({
for (i in 1:4)
sort(runif(n = 1e7, max = i))[1]
})
?runif
p <- runif(n=1e7)
p <- runif(n=1e7) %>% sort()
3^(-3)
foreach(i = 1:3, j = 0:-3, .combine = "c") %dopar% {i ^ j}
1:3
0:-3
(1:3) ^(0:-3)
(1:3) ^(0:-2)
`%:%`
?`%:%`
p <- 50
V <- foreach(i = 1:p, .combine = "cbind") %:%
foreach(j = 1:p, .combine = "c") %dopar% {
if (abs(i - j) < 5) {
rnorm(n = 1, sd = 1 + abs(i - j))
} else {
0
}
}
str(V)
V
?times
?times
x <- 1:2
x[3] <- 5
x
library(lobstr)
obj_addr(x)
x <- 1:2
obj_addr(x)
x[3] <- 5
obj_addr(x)
?ref
x <- rnorm(1e6)
y <- 1:1e6
z <- seq(1, 1e6, by = 1)
s <- (1:1e6) ^2
c(obj_size(x), obj_size(y), obj_size(z), obj_size(s))
bike <- read_csv("~/Downloads/cbs_2015.csv")
file.choose()
bike <- read_csv("cbs_2015.csv")
bike
library(vroom)
install.packages("vroom")
library(vroom)
vroom("cbs_2015.csv")
library(multidplyr)
install.packages("multidplyr")
devtools::install_github("tidyverse/multidplyr")
install.packages("devtools")
library(devtools)
devtools::install_github("tidyverse/multidplyr")
library(multidplyr)
clust <- multidplyr::new_cluster(3)
base_url <- "http://www2.stat.duke.edu/~sms185/data/bike/"
files <- c("cbs_2015.csv", "cbs_2016.csv", "cbs_2017.csv")
multidplyr::cluster_assign_partition(clust, file_name = paste0(base_url, files))
multidplyr::cluster_send(clust, cbs_data <- vroom::vroom(file_name))
cbs <- multidplyr::party_df(clust, "cbs_data")
cbs
cbs %>% DT::datatable()
cbs %>% as_tibble()
cbs[1:100,] %>% as_tibble()
dim(cbs)
1
cbs[1:100, ]
cbs[1, ]
cbs[1, ,]
p <- vroom("cbs_2015.csv")
p[1,]
p[1:30,] %>% DT::datatable()
stopCluster(clust)
clust
library(dbplyr)
library(dplyr)
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = ":memory:")
install.packages("RSQLite")
con <- DBI::dbConnect(RSQLite::SQLite(), dbname = ":memory:")
copy_to(con, df = nycflights13::airports, "airports")
DBI::dbListTables(con)
#> [1] "airports"     "sqlite_stat1" "sqlite_stat4"
airports_db <- tbl(con, "airports")
?tbl
airports_db
airport_timezone <- airports_db %>%
group_by(tzone) %>%
summarise(count = n())
airport_timezone
airport_timezone %>%
show_query()
airport_timezone
airport_car <- airports_db %>%
filter(lat >= 33.7666, lat <= 36.588, lon >= -84.3201, lon <= -75.4129) %>%
arrange(desc(alt)) %>%
select(name, alt)
airport_car %>%
show_query()
?collect
install.packages("Lahman")
library(RSQLite)
library(Lahman)
con <- dbConnect(RSQLite::SQLite(), ":memory:")
dbWriteTable(con, "batting", Batting)
dbWriteTable(con, "pitching", Pitching)
dbWriteTable(con, "teams", Teams)
dbListTables(con)
?format
format(1:10)
format(1:10, trim = TRUE)
install.packages("sf")
library(sf)
nc <- st_read(system.file("shape/nc.shp", package = "sf"), quiet = TRUE)
nc
plot(nc)
mapview(nc)
install.packages("mapview")
download.file("https://opendata.arcgis.com/datasets/faaad7fcca8d4f67abdbb1bd4697f055_0.zip",
destfile = "data/Gamelands.zip")
download.file("https://opendata.arcgis.com/datasets/faaad7fcca8d4f67abdbb1bd4697f055_0.zip", destfile = "data/Gamelands.zip")
download.file("https://opendata.arcgis.com/datasets/faaad7fcca8d4f67abdbb1bd4697f055_0.zip", destfile = "Gamelands.zip")
list.files()
unzip()
download.file("https://opendata.arcgis.com/datasets/84ff6d8f569f4bb0965bfa906aa06e6d_2.zip?outSR=%7B%22latestWkid%22%3A32119%2C%22wkid%22%3A32119%7D",
destfile = "waste.zip")
unzip("data/waste.zip", exdir = "data/")
unzip("waste.zip", exdir = "map/")
unzip("waste.zip", exdir = "map/")
unzip("waste.zip", exdir = "map")
unzip("waste.zip", exdir = "map/")
unzip("waste.zip", exdir = "")
unzip("waste.zip", exdir = file.choose())
durham_county <- nc %>%
filter(NAME == "Durham")
durham_county
durham_county %>% str()
nc[durham_county, ]
nc[durham_county, ] %>% str()
durham_county %>% str()
nc[durham_county, ] %>% str()
durham_county %>% DT::datatable()
nc[durham_county, ] %>% DT::datatable()
df <- data.frame(x = 1:10, y = letters[1:10])
df <- data.frame(x = 1:10, y = letters[1:10])
df.x <- data.frame(x = 1:5, y = letters[1:5])
df[df.x, ]
x <- 1:2
x[1:4]
install.packages("assertthat
")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
library(assertthat)
ls("package:assertthat")
apropos()
apropos(where = assert_that)
library(testthat)
?source
?auto_test
library(sparklyr)
install.packages("sparklyr")
library(sparklyr)
sparklyr::spark_available_versions()
spark_install(version = "3.0")
# create a spark connection
sc <- spark_connect(master = "local",
version = "3.0.0"
)
# create a spark connection
sc <- spark_connect(master = "local",
version = "3.0.0"
)
# create a spark connection
sc <- spark_connect(master = "local",
version = "3.0.0"
)
